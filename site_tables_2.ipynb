{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2264ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50973a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_Analysis():\n",
    "\n",
    "    # Create a function to clean the tweets\n",
    "    def cleanComments(self,text):\n",
    "        text = re.sub('@[A-Za-z0â€“9]+', '', text)  # Removing @mentions\n",
    "        text = re.sub('#', '', text)  # Removing '#' hash tag\n",
    "        text = re.sub('RT[\\s]+', '', text)  # Removing RT\n",
    "        text = re.sub('https?:\\/\\/\\S+', '', text)  # Removing hyperlink\n",
    "        return text\n",
    "\n",
    "    def scrape(self,keyword):\n",
    "        # Creating list to append tweet data\n",
    "        tweets_list = []\n",
    "\n",
    "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(keyword).get_items()):\n",
    "            if i > 10:\n",
    "                break\n",
    "            tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "\n",
    "        # Creating a dataframe from the tweets list above\n",
    "        #df = pd.read_csv(r'Twitter_omnicron.csv')\n",
    "        df = pd.DataFrame(tweets_list, columns=['Date', 'Tweet Id', 'Reviews', 'Username'])\n",
    "        df[\"Reviews\"] = df[\"Reviews\"].apply(self.cleanComments)\n",
    "        filename=r'Twitter_{0}.csv'.format(keyword.replace(\" \",\"_\"))\n",
    "        df.to_csv(filename)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def cleanTxt(self,df,keyword):\n",
    "        \n",
    "        ##Creating a list of stop words and adding custom stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        \n",
    "        corpus = []\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['Reviews']\n",
    "    \n",
    "            #Remove punctuations\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "            #Convert to lowercase\n",
    "            text = text.lower()\n",
    "    \n",
    "            #remove tags\n",
    "            text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "            # remove special characters and digits\n",
    "            text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "            ##Convert to list from string\n",
    "            text = text.split()\n",
    "    \n",
    "            text = \" \".join(text)\n",
    "\n",
    "            df.loc[index,'processed_reviews'] = text\n",
    "        \n",
    "        filename=r'Twitter_{0}.csv'.format(keyword.replace(\" \",\"_\"))\n",
    "        \n",
    "        df.drop_duplicates(subset=\"Reviews\",keep=\"first\",inplace=True)\n",
    "        df = df[df['Reviews'].notna()]\n",
    "        df.to_csv(filename)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('search.html')\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def show_tables():\n",
    "    #data = pd.read_csv(r'Twitter_Analyized.csv')\n",
    "    twitter = Twitter_Analysis()\n",
    "    keyword = request.form['keyword']\n",
    "    print(\"Entered keyword is ----->>>>\",keyword)#str(input(\"Enter search word-\"))\n",
    "    twitter_pd = twitter.scrape(keyword)#pd.read_csv(r'Twitter_Analyized.csv')\n",
    "    twitter_pd = twitter.cleanTxt(twitter_pd,keyword)\n",
    "    return render_template('view.html',tables=[twitter_pd.to_html(classes='report')])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e10f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3badcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
