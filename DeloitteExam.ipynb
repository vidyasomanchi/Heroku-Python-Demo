{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2264ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_Analysis():\n",
    "\n",
    "    # Create a function to clean the tweets\n",
    "    def cleanComments(self,text):\n",
    "        text = re.sub('@[A-Za-z0â€“9]+', '', text)  # Removing @mentions\n",
    "        text = re.sub('#', '', text)  # Removing '#' hash tag\n",
    "        text = re.sub('RT[\\s]+', '', text)  # Removing RT\n",
    "        text = re.sub('https?:\\/\\/\\S+', '', text)  # Removing hyperlink\n",
    "        return text\n",
    "\n",
    "    def scrape(self,keyword):\n",
    "        # Creating list to append tweet data\n",
    "        tweets_list = []\n",
    "\n",
    "        for i, tweet in enumerate(sntwitter.TwitterSearchScraper(keyword).get_items()):\n",
    "            if i > 10:\n",
    "                break\n",
    "            tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "\n",
    "        # Creating a dataframe from the tweets list above\n",
    "        #df = pd.read_csv(r'Twitter_omnicron.csv')\n",
    "        df = pd.DataFrame(tweets_list, columns=['Date', 'Tweet Id', 'Reviews', 'Username'])\n",
    "        df[\"Reviews\"] = df[\"Reviews\"].apply(self.cleanComments)\n",
    "        filename=r'Twitter_{0}.csv'.format(keyword.replace(\" \",\"_\"))\n",
    "        df.to_csv(filename)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def cleanTxt(self,df,keyword):\n",
    "        \n",
    "        ##Creating a list of stop words and adding custom stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        \n",
    "        corpus = []\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['Reviews']\n",
    "    \n",
    "            #Remove punctuations\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "            #Convert to lowercase\n",
    "            text = text.lower()\n",
    "    \n",
    "            #remove tags\n",
    "            text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "            # remove special characters and digits\n",
    "            text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "            ##Convert to list from string\n",
    "            text = text.split()\n",
    "    \n",
    "            text = \" \".join(text)\n",
    "\n",
    "            df.loc[index,'processed_reviews'] = text\n",
    "        \n",
    "        filename=r'Twitter_{0}.csv'.format(keyword.replace(\" \",\"_\"))\n",
    "        \n",
    "        df.drop_duplicates(subset=\"Reviews\",keep=\"first\",inplace=True)\n",
    "        df = df[df['Reviews'].notna()]\n",
    "        df.to_csv(filename)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def my_form():\n",
    "    return render_template('search.html')\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def show_tables():\n",
    "    #data = pd.read_csv(r'Twitter_Analyized.csv')\n",
    "    twitter = Twitter_Analysis()\n",
    "    keyword = request.form['keyword']\n",
    "    print(\"Entered keyword is ----->>>>\",keyword)#str(input(\"Enter search word-\"))\n",
    "    twitter_pd = twitter.scrape(keyword)#pd.read_csv(r'Twitter_Analyized.csv')\n",
    "    twitter_pd = twitter.cleanTxt(twitter_pd,keyword)\n",
    "    return render_template('view.html',tables=[twitter_pd.to_html(classes='report')])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e502846",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3badcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/ey383aw/OneDrive - EY/Documents/Vidya_practice/heroku_tables/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ff879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in .ipynb_checkpoints/site_tables-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in .ipynb_checkpoints/site_tables_2-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Twitter_Analyized.csv.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Twitter_omnicron.csv.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in site_tables.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in site_tables_2.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in site_tables_2.py.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6877b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) f31d26c] initial commit\n",
      " 17 files changed, 2181 insertions(+)\n",
      " create mode 100644 .ipynb_checkpoints/site_tables-checkpoint.ipynb\n",
      " create mode 100644 .ipynb_checkpoints/site_tables_2-checkpoint.ipynb\n",
      " create mode 100644 Procfile\n",
      " create mode 100644 Procfile.bak\n",
      " create mode 100644 Twitter_Analyized.csv\n",
      " create mode 100644 Twitter_omnicron.csv\n",
      " create mode 100644 dummy_data.xlsx\n",
      " create mode 100644 requirements.txt\n",
      " create mode 100644 site_tables.ipynb\n",
      " create mode 100644 site_tables_2.ipynb\n",
      " create mode 100644 site_tables_2.py\n",
      " create mode 100644 static/style.css\n",
      " create mode 100644 static/style.css.bak\n",
      " create mode 100644 templates/search.html\n",
      " create mode 100644 templates/search.html.bak\n",
      " create mode 100644 templates/view.html\n",
      " create mode 100644 templates/view.html.bak\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"initial commit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c7d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/vidyasomanchi/Heroku-Python-Demo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b66010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git branch -M main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e7b2ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0230d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
